{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import linear_rainbow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/mnt/data/tips (data for regression problem).csv')\n",
    "\n",
    "# 1. Data Analysis and Visualization\n",
    "\n",
    "# Scatter plot of total bill vs tip\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='total_bill', y='tip')\n",
    "plt.title('Total Bill vs Tip Amount')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix heatmap for numeric features\n",
    "plt.figure(figsize=(10, 8))\n",
    "numeric_cols = ['total_bill', 'tip', 'size']\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Pair plot to visualize relationships between numeric variables\n",
    "sns.pairplot(df[numeric_cols])\n",
    "plt.show()\n",
    "\n",
    "# Box plots for categorical variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "sns.boxplot(data=df, x='sex', y='tip', ax=axes[0, 0])\n",
    "sns.boxplot(data=df, x='smoker', y='tip', ax=axes[0, 1])\n",
    "sns.boxplot(data=df, x='day', y='tip', ax=axes[1, 0])\n",
    "sns.boxplot(data=df, x='time', y='tip', ax=axes[1, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "# Split features and target\n",
    "X = df.drop('tip', axis=1)\n",
    "y = df['tip']\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_features = ['total_bill', 'size']\n",
    "categorical_features = ['sex', 'smoker', 'day', 'time']\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first', sparse_output=False)  # Fixed here\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Linearity Check - Rainbow Test\n",
    "X_const = sm.add_constant(X[numeric_features])  # Adding a constant for OLS\n",
    "model = sm.OLS(y, X_const).fit()\n",
    "rainbow_stat, rainbow_p_val = linear_rainbow(model)\n",
    "\n",
    "print(\"Rainbow Test:\")\n",
    "print(\"Statistic:\", rainbow_stat)\n",
    "print(\"p-value:\", rainbow_p_val)\n",
    "if rainbow_p_val > 0.05:\n",
    "    print(\"No significant departure from linearity.\")\n",
    "else:\n",
    "    print(\"Significant non-linearity detected.\")\n",
    "\n",
    "# 4. Model Building and Evaluation with Hyperparameter Tuning\n",
    "def evaluate_model(model, name, param_grid=None):\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    if param_grid:\n",
    "        # Perform grid search for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        # Standard fit without grid search\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        best_params = None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "    \n",
    "    return {\n",
    "        'Model': name,\n",
    "        'MSE': mse,\n",
    "        'R2 Score': r2,\n",
    "        'CV Score Mean': cv_scores.mean(),\n",
    "        'CV Score Std': cv_scores.std(),\n",
    "        'Best Params': best_params\n",
    "    }\n",
    "\n",
    "# Define models with parameter grids for hyperparameter tuning\n",
    "models = {\n",
    "    'Linear Regression': (LinearRegression(), None),\n",
    "    'Ridge Regression': (Ridge(), {'regressor__alpha': [0.1, 1.0, 10.0]}),\n",
    "    'Lasso Regression': (Lasso(), {'regressor__alpha': [0.01, 0.1, 1.0]}),\n",
    "    'Decision Tree': (DecisionTreeRegressor(random_state=42), {'regressor__max_depth': [3, 5, 10, None]}),\n",
    "    'Random Forest': (RandomForestRegressor(random_state=42), {'regressor__n_estimators': [50, 100, 150], 'regressor__max_depth': [3, 5, 10, None]}),\n",
    "    'SVR': (SVR(), {'regressor__C': [0.1, 1, 10], 'regressor__gamma': ['scale', 'auto']}),\n",
    "    'KNN': (KNeighborsRegressor(), {'regressor__n_neighbors': [3, 5, 7, 10]})\n",
    "}\n",
    "\n",
    "# Evaluate all models\n",
    "results = []\n",
    "for name, (model, param_grid) in models.items():\n",
    "    results.append(evaluate_model(model, name, param_grid))\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# 5. Feature Importance Analysis (using Random Forest)\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "feature_importances = rf_pipeline.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names = (numeric_features + \n",
    "                [f\"{feat}_{val}\" for feat, vals in \n",
    "                 zip(categorical_features, \n",
    "                     rf_pipeline.named_steps['preprocessor']\n",
    "                     .named_transformers_['cat'].categories_) \n",
    "                 for val in vals[1:]])\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature')\n",
    "plt.title('Feature Importance Analysis')\n",
    "plt.show()\n",
    "\n",
    "# 6. Residual Analysis for Best Model (Random Forest)\n",
    "best_model = rf_pipeline\n",
    "y_pred = best_model.predict(X_test)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}